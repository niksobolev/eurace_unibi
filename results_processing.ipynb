{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import plotly.express as px\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.fftpack\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a list of days to read from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_days = 72000\n",
    "step = 60\n",
    "current_day_list = 51480\n",
    "file_names_list = []\n",
    "days_to_iterate = current_day_list + num_of_days\n",
    "    \n",
    "while current_day_list < days_to_iterate-step:\n",
    "    current_day_list += step\n",
    "    file_names_list.append(current_day_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from directories\n",
    "Don't forget to set a variable with a number of samples (folders) with experiments in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 10\n",
    "root_path = '/data/home/nsov/eurace/original/reproduce_results/'\n",
    "\n",
    "qe_list = [1, 0]\n",
    "# dividents = [0.5, 0.7, 0.9]\n",
    "dividents = [0.8]\n",
    "dict_of_dataframes = {}\n",
    "last_day = max(file_names_list)\n",
    "\n",
    "for div in dividents:\n",
    "    case_name = 'test_div_' + str(div)\n",
    "    dict_of_dataframes[case_name] = pd.DataFrame()\n",
    "    for sample in range(number_of_samples):\n",
    "        dir_name = case_name + '_' + str(sample)\n",
    "        current_dir = root_path + dir_name\n",
    "        try:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            for file in file_names_list: \n",
    "                if file == 0:\n",
    "                    xml_data = open(current_dir + '/{}.xml'.format('0_initial'), 'r').read()  # Read file\n",
    "                else:\n",
    "                    xml_data = open(current_dir + '/{}.xml'.format(file), 'r').read()  # Read file\n",
    "                root = ET.XML(xml_data)  # Parse XML\n",
    "\n",
    "                data = []\n",
    "                cols = []\n",
    "                names = []\n",
    "                for i, child in enumerate(root):\n",
    "                    try:\n",
    "                        names.append(child.find('name').text)\n",
    "                    except:\n",
    "                        pass\n",
    "                    if child.tag == 'xagent':\n",
    "                        if child.find('name').text == 'Eurostat':\n",
    "                            data.append([subchild.text for subchild in child])\n",
    "                            if file == last_day:\n",
    "                                cols = [subchild.tag for subchild in child]\n",
    "                df2 = pd.DataFrame(data)\n",
    "                df = pd.concat([df, df2], ignore_index=True)\n",
    "                if file == last_day:\n",
    "                    df.columns = cols  # Update column names\n",
    "            df['case_number'] = [sample] * len(df)\n",
    "            dict_of_dataframes[case_name] = pd.concat([dict_of_dataframes[case_name], df])\n",
    "            print('Done for ' + dir_name)\n",
    "        except:\n",
    "            print('Error for ' + dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for sliding window over time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield sum(result)/n\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield sum(result)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT function for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_window_size = 4 #The size of a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fft_plot(unemployment_series, variable, case):\n",
    "    mean_of_series = unemployment_series.mean()\n",
    "    # If you want to use fft with sliding window function to erase high frequency noise uncomment folowing line\n",
    "    unemployment_window = list(i - unemployment_series.mean()  for i in window(unemployment_series, n=set_window_size))\n",
    "    # If you want to use fft without sliding window function to leave high frequency noise uncomment folowing line\n",
    "#     unemployment_window = list(i - unemployment_series.mean()  for i in unemployment_series)\n",
    "    # If you want to use butterworth filer to erase high frequency noise uncomment folowing line\n",
    "#     unemployment_window = list(i - mean_of_series  for i in my_butterworth(unemployment_series))\n",
    "\n",
    "    fft_unemp_complex = np.fft.rfft(unemployment_window)\n",
    "    fft_unemp = []\n",
    "    for i in fft_unemp_complex:\n",
    "        fft_unemp.append(abs(i))\n",
    "    func_to_draw = fft_unemp\n",
    "    n = len(unemployment_window)\n",
    "    \n",
    "    x = np.fft.rfftfreq(n, d=1)\n",
    "\n",
    "    fig = go.Figure([\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            # You can youse square function to make fft peaks more obvious\n",
    "#             y=np.square(func_to_draw),\n",
    "            # Or draw original fft function\n",
    "            y=func_to_draw,\n",
    "            line=dict(color='rgb(0,100,80)'),\n",
    "            mode='lines'\n",
    "        )\n",
    "    ])\n",
    "    fig.update_layout(xaxis_title='Frequency',\n",
    "                     yaxis_title='Magnitude of the FFT')\n",
    "    fig.write_html(\"fft_{variable}_{case}.html\".format(variable=variable, case=case))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterworth low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_butterworth(input_series):\n",
    "    sos = signal.butter(10, 0.2*len(input_series), 'lp', fs=len(input_series), output='sos')\n",
    "    filtered = signal.sosfilt(sos, input_series)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set dicts of colors for different dividends ratios that will be used for drawing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_line_dict = {0.3: 'rgb(150,0,0)',0.5: 'rgb(150,0,0)', 0.7 : 'rgb(0,150,0)', 0.8 : 'rgb(0,0,150)' }\n",
    "rgb_error_dict = {0.3: 'rgba(150,0,0,0.2)',0.5: 'rgb(150,0,0)', 0.7 : 'rgba(0,150,0,0.2)', 0.8 : 'rgba(0,0,150,0.2)' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some variables for choosing what to draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1\n",
    "root_path = '/data/home/nsov/eurace/original/reproduce_results/'\n",
    "\n",
    "qe_list = [1]\n",
    "# dividents = [0.5, 0.7, 0.9]\n",
    "dividents = [0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function counts mean and std for a certain serie from dict of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(case_name, input_series, growth_rate=False):\n",
    "    dict_of_dataframes[case_name][input_series] = pd.to_numeric(dict_of_dataframes[case_name][input_series])\n",
    "    variable_frame = dict_of_dataframes[case_name][input_series].to_frame()\n",
    "    variable_series = variable_frame.groupby(variable_frame.index).mean()[input_series]\n",
    "    \n",
    "    # FFT analysis has shown that there are two main harmonics of time series:\n",
    "    #    1 year cycle (main harmonc)\n",
    "    #    half year cycle \n",
    "    # So if we take average value of the main harmonics with half period interval, we can get accurate average value.\n",
    "    # Here are experiments for 1 harmonic averaging: 2 points with 0.5 year step\n",
    "    # experiment of averaging over 2 harmonics: 4 points with 0.25 year step\n",
    "    # and aditional experiment for whole year averaging: 12 points with 1 month step\n",
    "    \n",
    "#     # experiment with 3 timestamps averaging\n",
    "#     unemployment_series = (unemployment_series + unemployment_series[3:].reset_index(drop=True) +\n",
    "#                            unemployment_series[6:].reset_index(drop=True) + unemployment_series[9:].reset_index(drop=True))/4\n",
    "#     unemployment_series = unemployment_series.dropna()\n",
    "\n",
    "# #         experiment with 6 timestamps averaging\n",
    "#     unemployment_series = (unemployment_series + unemployment_series[6:].reset_index(drop=True))/2\n",
    "#     unemployment_series = unemployment_series.dropna()\n",
    "    \n",
    "    #         experiment with 1 year timestamps averaging\n",
    "#     unemployment_series_loop = unemployment_series\n",
    "#     for i in range(1,12):\n",
    "#         unemployment_series = unemployment_series + unemployment_series_loop[i:].reset_index(drop=True)\n",
    "#     unemployment_series = unemployment_series/12\n",
    "#     unemployment_series = unemployment_series.dropna()\n",
    "    \n",
    "    variable_series_std = variable_frame.groupby(variable_frame.index).std()[input_series]\n",
    "    \n",
    "    if growth_rate == True:\n",
    "        variable_series = variable_series.diff()/variable_series\n",
    "        variable_series = growth_rate_series.dropna()\n",
    "        variable_series_std = variable_series_std.diff()/variable_series\n",
    "        variable_series_std = variable_series_std.dropna()\n",
    "    \n",
    "    return variable_series, variable_series_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables that you want to track and their names that will be displayed on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_variables = ['gdp', 'unemployment_rate', 'cpi', 'average_wage', 'firm_average_productivity_progress', 'employment_rate', 'monthly_investment_value', 'monthly_output']\n",
    "plot_names = {'gdp' : 'GDP growth rate', 'unemployment_rate': 'Unemployment rate', 'cpi': 'CPI',\n",
    "             'average_wage': 'Average wage growth rate', 'firm_average_productivity_progress': 'Firm average productivity progress',\n",
    "             'employment_rate' : 'Employment rate', 'monthly_investment_value': 'Monthly investment value',\n",
    "             'monthly_output': 'Monthly output'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main counting cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxplot = pd.DataFrame()\n",
    "\n",
    "list_of_lines_gdp = []\n",
    "stabilization_offset = 25 # the number of iteration for model stabilization. \n",
    "                          # We will not use these iterations for counting numerical results\n",
    "\n",
    "# Dict where series of values will be saved for building plots\n",
    "dict_of_lines= {}\n",
    "for i in output_variables:\n",
    "    dict_of_lines[i] = []\n",
    "\n",
    "# Iterate dividends values\n",
    "for div in dividents:\n",
    "    # This dict will be used for building boxplots\n",
    "    long_stay_dict = {}\n",
    "    case_name = 'test_div_' + str(div)\n",
    "    \n",
    "    # For each variable compute mean, std and save a list of values for a plot\n",
    "    for variable in output_variables:\n",
    "        # For this variables count its growth rate mean and std instead of absolute values\n",
    "        if variable == 'average_wage' or 'gdp':\n",
    "            var_mean, var_std = get_series(case_name, variable, growth_rate = True)\n",
    "        else:\n",
    "            var_mean, var_std = get_series(case_name, variable)\n",
    "        \n",
    "        # Print mean, std and mean of std for variables in the list\n",
    "        print(str(variable), ' mean: ', \"{:.4}\".format(var_mean[stabilization_offset:].mean()))\n",
    "        print(str(variable), ' std_mean: ', \"{:.4}\".format(var_mean[stabilization_offset:].std()))\n",
    "        print(str(variable), ' std: ', \"{:.4}\".format(var_std[stabilization_offset:].mean()))\n",
    "        \n",
    "        #Save these values for building boxplots\n",
    "        long_stay_dict[variable] = [var_mean, var_std]\n",
    "        \n",
    "        # Draw interactive html plots with plotly\n",
    "        x = list(var_mean.index)\n",
    "        y = list(var_mean)\n",
    "        y_err_up = list(var_mean + var_std)\n",
    "        y_err_down = list(var_mean - var_std)\n",
    "\n",
    "        dict_of_lines[variable].append(\n",
    "            go.Scatter(\n",
    "                name=str('Quantitative easing ')+str(div),\n",
    "                x=x,\n",
    "                y=pd.Series(i for i in window(y, n=set_window_size)),\n",
    "                #If you want to use butterworth filter uncomment following line\n",
    "                #y=my_butterworth(y)\n",
    "                line=dict(color=rgb_line_dict[div]),\n",
    "                mode='lines'\n",
    "            ))\n",
    "        dict_of_lines[variable].append(\n",
    "            go.Scatter(\n",
    "                name=str('Quantitative easing')+' (std) '+str(div),\n",
    "                x=x+x[::-1], # x, then x reversed\n",
    "                y=y_err_up+y_err_down[::-1], # upper, then lower reversed\n",
    "                fill='toself',\n",
    "                fillcolor=rgb_error_dict[div],\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=True\n",
    "            ))\n",
    "\n",
    "    #draw fft plot for a variable\n",
    "    draw_fft_plot(long_stay_dict['unemployment_rate'][0][0:], 'unemployment', str(div))\n",
    "\n",
    "    df_local_boxplot = pd.DataFrame({'Unemployment': unemployment_series.iloc[stabilization_offset:], 'GDP growth rate': growth_rate_series.iloc[stabilization_offset:], 'Dividents' : [div] * len(unemployment_series.iloc[stabilization_offset:])})\n",
    "    df_boxplot= pd.concat([df_boxplot, df_local_boxplot], ignore_index=True)\n",
    "\n",
    "# Pass lists to plotly and build all plots\n",
    "for variable in dict_of_lines.keys():\n",
    "    fig = go.Figure(dict_of_lines[variable])\n",
    "    fig.update_layout(legend_title_text = 'Case',\n",
    "                     xaxis_title='Month',\n",
    "                     yaxis_title=plot_names[variable])\n",
    "    fig.write_html(plot_names[variable]+\".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build boxplots\n",
    "I was saving datasets with different policies to different datasets.\\\n",
    "Scripts above give all information for one policy case for different dividends payout ratios.\\\n",
    "Thus, if I want to campare results of two different policies I load a dataframe with one policy.\\\n",
    "Then I run main counting cell and save dict of lines to \"qe_dict\".\\\n",
    "After that I load another policy case, run main counting cell and save data to \"std_dict\".\\\n",
    "And the I compare these two policies.\\\n",
    "I could do it more elegant way, but I needed this part only once and I'm too lazy to change it:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_dict = dict_of_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dict = dict_of_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_lines2 = {}\n",
    "for i in output_variables:\n",
    "    dict_of_lines2[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dict_of_lines:\n",
    "    dict_of_lines2[i] = []\n",
    "    for item in qe_dict[i]:\n",
    "        dict_of_lines2[i].append(item)\n",
    "    for item in std_dict[i]:\n",
    "        dict_of_lines2[i].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_lines2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standart_dict = long_stay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quntitative_dict = long_stay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in standart_dict.keys():\n",
    "    df_local = pd.DataFrame({plot_names[i]: standart_dict[i][0][600:], 'case' : ['No policy'] * len(standart_dict[i][0][600:])})\n",
    "    df_local = pd.concat([df_local, pd.DataFrame({plot_names[i]: quntitative_dict[i][0][600:], 'case' : ['Quantitative easing'] * len(quntitative_dict[i][0][600:])})], ignore_index=True)\n",
    "    \n",
    "    fig = px.box(df_local, x = 'case', y = plot_names[i])\n",
    "    fig.write_html('bp_' + str(i) +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()\n",
    "for key, dataframe in dict_of_dataframes.items():\n",
    "    dataframe['case_name'] = [key]*len(dataframe)\n",
    "full_df = pd.concat(dict_of_dataframes.values())\n",
    "full_df.to_csv('initial_state_300_years_08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df2 = pd.read_csv('standart_2k.csv', index_col= 'Unnamed: 0')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_dataframes = {}\n",
    "for i in list(full_df2.case_name.unique()):\n",
    "    dict_of_dataframes[i] = full_df2.loc[full_df2.case_name == i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "#### Does not work anymore!\n",
    "I thought I would count correlation between two series with different offset one to another, but I don't need to.\\\n",
    "I will leave this part of code just in case if I will change my mind :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 2\n",
    "start_position = len(df_corr.unemployment_series)//2\n",
    "correlation_change = []\n",
    "for i in range(years*2*12):\n",
    "    correlation_change.append(np.corrcoef(df_corr.unemployment_series[start_position-years*12+i:start_position+i], df_corr.growth_rate_series[start_position-years*12+i:start_position+i])[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(correlation_change)))\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=correlation_change,\n",
    "        line=dict(color='rgb(0,100,80)'),\n",
    "        mode='lines'\n",
    "    )\n",
    "])\n",
    "fig.write_html(\"correlation_change.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 1\n",
    "start_position = len(df_corr.unemployment_series)//4\n",
    "\n",
    "min_month = []\n",
    "corr_val = []\n",
    "for shift in range(start_position*2):\n",
    "    correlation_change = []\n",
    "    for i in range(years*2*12):\n",
    "        correlation_change.append(np.corrcoef(df_corr.unemployment_series[start_position-years*12+i+shift:start_position+i+shift], df_corr.growth_rate_series[start_position-years*12+shift:start_position+shift])[0,1])\n",
    "    min_month.append(correlation_change.index(min(correlation_change)) - years*12)\n",
    "    corr_val.append(min(correlation_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(x=min_month, nbins = years*2*24)\n",
    "fig.write_html(\"correlation_hist.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
